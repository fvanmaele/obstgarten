% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pruning.R
\name{cart_greedy_prune}
\alias{cart_greedy_prune}
\title{Cost-Complexity pruning of greedy CART}
\usage{
cart_greedy_prune(
  XY,
  depth = 10L,
  mode = "regression",
  threshold = 1L,
  random = FALSE,
  m = 0L,
  quantile = FALSE,
  q_threshold = 100L,
  q_pct = 0.25,
  lambda = 0.01,
  use_parallel = FALSE
)
}
\arguments{
\item{XY}{matrix with columns \eqn{1..d} (representing the training data
\eqn{X_i}) and column \eqn{y} (for the values \eqn{Y_i}).}

\item{depth}{The amount of steps before halting the algorithm (defaults to
10)}

\item{mode}{\code{regression} or \code{classification} specifies whether to train
a regression or classification tree, respectively. Default is "regression"}

\item{threshold}{The minimum amount of data points for dividing a leaf (\code{integer})}

\item{random}{generates CART for random forest (\code{logical}, default \code{FALSE})}

\item{m}{The
default: 0 so it only has to be set at random=TRUE (\code{numeric})}

\item{quantile}{whether to use quantiles for computing the optimal
subdivision (\code{logical}, defaults to \code{FALSE})}

\item{q_threshold}{minimal of data points for using quantiles (\code{integer},
defaults to \code{100L})}

\item{q_pct}{amount of probabilities for \code{quantile()}, in pct. of the data
set size. (\code{numeric}, defaults to \code{0.25})}

\item{lambda}{weight for complexity-cost}

\item{use_parallel}{logical: whether to use parallel computation or not}
}
\value{
A regression or classification tree modeled after the training data
(\code{Baum}), pruned according to Cost-Complexity
}
\description{
Create a regression or classification tree greedily based
on training data. Then prune it according to cost-complexity trade-off
}
\examples{
cart_greedy_prune(generate_sin_data(100, sigma=0.2), depth=5, threshold=1, lambda = 0.01)
}
